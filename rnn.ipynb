{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from optuna import Trial, Study\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "from utils.training import train, best_torch_device, tutorial_train\n",
    "from torchinfo import summary\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = best_torch_device()\n",
    "# device = torch.device('cpu')\n",
    "print(best_torch_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid = np.load(\"data/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"data/y_train_valid.npy\")\n",
    "person_train_valid = np.load(\"data/person_train_valid.npy\")\n",
    "\n",
    "X_train_aug = np.load(\"data/generated/frequency/X_train_augmented.npy\")\n",
    "y_train_aug = np.load(\"data/generated/frequency/y_train_augmented.npy\")\n",
    "\n",
    "X_test = np.load(\"data/X_test.npy\")\n",
    "y_test = np.load(\"data/y_test.npy\")\n",
    "person_test = np.load(\"data/person_test.npy\")\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_train_aug -= 769\n",
    "y_test -= 769\n",
    "\n",
    "X_train = X_train_valid[:1777]\n",
    "y_train = y_train_valid[:1777]\n",
    "X_valid = X_train_valid[1777:]\n",
    "y_valid = y_train_valid[1777:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1777, 22, 1000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        conv1_filter_num = 32\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=22, out_channels=conv1_filter_num, kernel_size=(5, 1), padding=(5, 0)),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 1)),\n",
    "            nn.BatchNorm2d(conv1_filter_num),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        conv2_filter_num = 128\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=conv1_filter_num, out_channels=conv2_filter_num, kernel_size=(5, 1), padding=(5, 0)),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 1)),\n",
    "            nn.BatchNorm2d(conv2_filter_num),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        conv3_filter_num = 128\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=conv2_filter_num, out_channels=conv3_filter_num, kernel_size=(5, 1), padding=(5, 0)),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 1)),\n",
    "            nn.BatchNorm2d(conv3_filter_num),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        conv_out_filter_size = 19\n",
    "        self.flatten = nn.Flatten(start_dim=2)\n",
    "        self.linear1 = nn.Linear(in_features=conv_out_filter_size, out_features=conv_out_filter_size)\n",
    "\n",
    "        self.flatten_cnn = nn.Flatten(start_dim=1)\n",
    "        self.linear_cnn = nn.Linear(in_features=conv_out_filter_size*conv3_filter_num, out_features=4)\n",
    "\n",
    "        self.tdd = nn.Linear(in_features=1000, out_features=50)\n",
    "\n",
    "        conv_rnn_filter_num = 50\n",
    "        self.conv_rnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=22, out_channels=conv_rnn_filter_num, kernel_size=(64, 1), padding=(5, 0)),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(7, 1)),\n",
    "            nn.BatchNorm2d(conv_rnn_filter_num),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.num_layers = 3\n",
    "        self.hidden_size = 30\n",
    "        self.lstm = nn.LSTM(input_size=conv3_filter_num, hidden_size=self.hidden_size, dropout=0.5, num_layers=self.num_layers)\n",
    "        # self.lstm = nn.LSTM(input_size=conv_rnn_filter_num, hidden_size=self.hidden_size, dropout=0.5, num_layers=self.num_layers)\n",
    "        \n",
    "        self.linear2 = nn.Linear(in_features=self.hidden_size, out_features=4) # (N, 4)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1) # the dim corresponds to num_output_classes=4\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x should have shape (N, H, L) = (N, 22, 1000), where\n",
    "            L = sequence length\n",
    "            N = batch size\n",
    "            H = input size\n",
    "        \"\"\"\n",
    "        (N, H, L) = x.shape\n",
    "\n",
    "        x = x.view((-1, 22, 1000, 1))\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        # x = self.linear1(x)\n",
    "        # x = self.flatten_cnn(x)\n",
    "        # x = self.linear_cnn(x)\n",
    "\n",
    "        # x = self.tdd(x)\n",
    "        # x = x.view((-1, 22, 1000, 1))\n",
    "        # x = self.conv_rnn(x)\n",
    "        # x = self.flatten(x)\n",
    "        x = x.permute(2, 0, 1) # permute to (L=time, N, H=channel_in)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # device = torch.device('mps')\n",
    "        # h0 = torch.randn(self.num_layers, N, self.hidden_size).to(device)\n",
    "        # c0 = torch.randn(self.num_layers, N, self.hidden_size).to(device)\n",
    "        # x, _ = self.lstm(x, (h0, c0))\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear2(x[-1]) # take the last time step\n",
    "        \n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        conv1_filter_num = 32\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=22, out_channels=conv1_filter_num, kernel_size=(5, 1), padding=(5, 0)),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 1)),\n",
    "            nn.BatchNorm2d(conv1_filter_num),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        conv2_filter_num = 128\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=conv1_filter_num, out_channels=conv2_filter_num, kernel_size=(5, 1), padding=(5, 0)),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 1)),\n",
    "            nn.BatchNorm2d(conv2_filter_num),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        conv3_filter_num = 128\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=conv2_filter_num, out_channels=conv3_filter_num, kernel_size=(5, 1), padding=(5, 0)),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 1)),\n",
    "            nn.BatchNorm2d(conv3_filter_num),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        conv_out_filter_size = 19\n",
    "        self.flatten = nn.Flatten(start_dim=2)\n",
    "        self.linear1 = nn.Linear(in_features=conv_out_filter_size, out_features=conv_out_filter_size)\n",
    "\n",
    "        self.flatten_cnn = nn.Flatten(start_dim=1)\n",
    "        self.linear_cnn = nn.Linear(in_features=conv_out_filter_size*conv3_filter_num, out_features=4)\n",
    "\n",
    "        self.tdd = nn.Linear(in_features=1000, out_features=50)\n",
    "\n",
    "        conv_rnn_filter_num = 50\n",
    "        self.conv_rnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=22, out_channels=conv_rnn_filter_num, kernel_size=(64, 1), padding=(5, 0)),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(7, 1)),\n",
    "            nn.BatchNorm2d(conv_rnn_filter_num),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.num_layers = 3\n",
    "        self.hidden_size = 30\n",
    "        self.lstm = nn.LSTM(input_size=conv3_filter_num, hidden_size=self.hidden_size, dropout=0.5, num_layers=self.num_layers)\n",
    "        # self.lstm = nn.LSTM(input_size=conv_rnn_filter_num, hidden_size=self.hidden_size, dropout=0.5, num_layers=self.num_layers)\n",
    "        \n",
    "        self.linear2 = nn.Linear(in_features=self.hidden_size, out_features=4) # (N, 4)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1) # the dim corresponds to num_output_classes=4\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x should have shape (N, H, L) = (N, 22, 1000), where\n",
    "            L = sequence length\n",
    "            N = batch size\n",
    "            H = input size\n",
    "        \"\"\"\n",
    "        (N, H, L) = x.shape\n",
    "\n",
    "        x = x.view((-1, 22, 1000, 1))\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        # x = self.linear1(x)\n",
    "        # x = self.flatten_cnn(x)\n",
    "        # x = self.linear_cnn(x)\n",
    "\n",
    "        # x = self.tdd(x)\n",
    "        # x = x.view((-1, 22, 1000, 1))\n",
    "        # x = self.conv_rnn(x)\n",
    "        # x = self.flatten(x)\n",
    "        x = x.permute(2, 0, 1) # permute to (L=time, N, H=channel_in)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # device = torch.device('mps')\n",
    "        # h0 = torch.randn(self.num_layers, N, self.hidden_size).to(device)\n",
    "        # c0 = torch.randn(self.num_layers, N, self.hidden_size).to(device)\n",
    "        # x, _ = self.lstm(x, (h0, c0))\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear2(x[-1]) # take the last time step\n",
    "        \n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "RNN                                      [128, 4]                  130,712\n",
       "├─Sequential: 1-1                        [128, 32, 335, 1]         --\n",
       "│    └─Conv2d: 2-1                       [128, 32, 1006, 1]        3,552\n",
       "│    └─ELU: 2-2                          [128, 32, 1006, 1]        --\n",
       "│    └─AvgPool2d: 2-3                    [128, 32, 335, 1]         --\n",
       "│    └─BatchNorm2d: 2-4                  [128, 32, 335, 1]         64\n",
       "│    └─Dropout: 2-5                      [128, 32, 335, 1]         --\n",
       "├─Sequential: 1-2                        [128, 128, 113, 1]        --\n",
       "│    └─Conv2d: 2-6                       [128, 128, 341, 1]        20,608\n",
       "│    └─ELU: 2-7                          [128, 128, 341, 1]        --\n",
       "│    └─AvgPool2d: 2-8                    [128, 128, 113, 1]        --\n",
       "│    └─BatchNorm2d: 2-9                  [128, 128, 113, 1]        256\n",
       "│    └─Dropout: 2-10                     [128, 128, 113, 1]        --\n",
       "├─Sequential: 1-3                        [128, 128, 39, 1]         --\n",
       "│    └─Conv2d: 2-11                      [128, 128, 119, 1]        82,048\n",
       "│    └─ELU: 2-12                         [128, 128, 119, 1]        --\n",
       "│    └─AvgPool2d: 2-13                   [128, 128, 39, 1]         --\n",
       "│    └─BatchNorm2d: 2-14                 [128, 128, 39, 1]         256\n",
       "│    └─Dropout: 2-15                     [128, 128, 39, 1]         --\n",
       "├─Flatten: 1-4                           [128, 128, 39]            --\n",
       "├─LSTM: 1-5                              [39, 128, 30]             34,080\n",
       "├─Linear: 1-6                            [128, 4]                  124\n",
       "├─Softmax: 1-7                           [128, 4]                  --\n",
       "==========================================================================================\n",
       "Total params: 271,700\n",
       "Trainable params: 271,700\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.78\n",
       "==========================================================================================\n",
       "Input size (MB): 11.26\n",
       "Forward/backward pass size (MB): 125.36\n",
       "Params size (MB): 0.56\n",
       "Estimated Total Size (MB): 137.19\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsz = 128\n",
    "sample_device = torch.device('mps')\n",
    "sample_model = RNN().to(sample_device)\n",
    "test_input = torch.randn(128, 22, 1000).to(sample_device)\n",
    "print(sample_model(test_input).shape)\n",
    "summary(sample_model, (bsz, 22, 1000), device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 42 3 4\n",
      "(5331, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "bsz = 128\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train)), shuffle=True, batch_size=bsz)\n",
    "train_aug_loader = DataLoader(TensorDataset(torch.from_numpy(X_train_aug), torch.from_numpy(y_train_aug)), shuffle=True, batch_size=bsz)\n",
    "val_loader = DataLoader(TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid)), shuffle=False, batch_size=bsz)\n",
    "test_loader = DataLoader(TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test)), shuffle=False, batch_size=bsz)\n",
    "\n",
    "print(len(train_loader), len(train_aug_loader), len(val_loader), len(test_loader))\n",
    "\n",
    "print(X_train_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(22, 32, kernel_size=(5, 1), stride=(1, 1), padding=(5, 0))\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): AvgPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0)\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 128, kernel_size=(5, 1), stride=(1, 1), padding=(5, 0))\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): AvgPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(5, 1), stride=(1, 1), padding=(5, 0))\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): AvgPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=2, end_dim=-1)\n",
      "  (linear1): Linear(in_features=19, out_features=19, bias=True)\n",
      "  (flatten_cnn): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_cnn): Linear(in_features=2432, out_features=4, bias=True)\n",
      "  (tdd): Linear(in_features=1000, out_features=50, bias=True)\n",
      "  (conv_rnn): Sequential(\n",
      "    (0): Conv2d(22, 50, kernel_size=(64, 1), stride=(1, 1), padding=(5, 0))\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): AvgPool2d(kernel_size=(7, 1), stride=(7, 1), padding=0)\n",
      "    (3): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (lstm): LSTM(128, 30, num_layers=3, dropout=0.5)\n",
      "  (linear2): Linear(in_features=30, out_features=4, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "torch.Size([128, 4])\n"
     ]
    }
   ],
   "source": [
    "model = RNN().to(device)\n",
    "print(model)\n",
    "num_chans, sequence_length = 22, 1000  # Image dimensions\n",
    "test_input = torch.randn(bsz, num_chans, sequence_length).to(device)\n",
    "print(model(test_input).shape)\n",
    "# pred = model(test_input)[0]\n",
    "# print(nn.CrossEntropyLoss()(pred, torch.from_numpy(y_train[0:1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70b494088be455aa78b69b20fb57d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.258, Val acc: 0.243\n",
      "Train acc: 0.261, Val acc: 0.272\n",
      "Train acc: 0.276, Val acc: 0.254\n",
      "Train acc: 0.274, Val acc: 0.269\n",
      "Train acc: 0.252, Val acc: 0.269\n",
      "Train acc: 0.260, Val acc: 0.278\n",
      "Train acc: 0.255, Val acc: 0.257\n",
      "Train acc: 0.258, Val acc: 0.260\n",
      "Train acc: 0.261, Val acc: 0.251\n",
      "Train acc: 0.252, Val acc: 0.263\n",
      "Train acc: 0.252, Val acc: 0.260\n",
      "Train acc: 0.257, Val acc: 0.266\n",
      "Train acc: 0.258, Val acc: 0.266\n",
      "Train acc: 0.251, Val acc: 0.272\n",
      "Train acc: 0.252, Val acc: 0.269\n",
      "Train acc: 0.253, Val acc: 0.269\n",
      "Train acc: 0.245, Val acc: 0.263\n",
      "Train acc: 0.252, Val acc: 0.275\n",
      "Train acc: 0.255, Val acc: 0.257\n",
      "Train acc: 0.255, Val acc: 0.260\n",
      "Train acc: 0.254, Val acc: 0.275\n",
      "Train acc: 0.252, Val acc: 0.260\n",
      "Train acc: 0.252, Val acc: 0.234\n",
      "Train acc: 0.263, Val acc: 0.257\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.272\n",
      "Train acc: 0.254, Val acc: 0.243\n",
      "Train acc: 0.252, Val acc: 0.257\n",
      "Train acc: 0.255, Val acc: 0.260\n",
      "Train acc: 0.247, Val acc: 0.254\n",
      "Train acc: 0.249, Val acc: 0.263\n",
      "Train acc: 0.257, Val acc: 0.257\n",
      "Train acc: 0.256, Val acc: 0.257\n",
      "Train acc: 0.256, Val acc: 0.254\n",
      "Train acc: 0.256, Val acc: 0.249\n",
      "Train acc: 0.254, Val acc: 0.260\n",
      "Train acc: 0.255, Val acc: 0.257\n",
      "Train acc: 0.256, Val acc: 0.249\n",
      "Train acc: 0.253, Val acc: 0.251\n",
      "Train acc: 0.255, Val acc: 0.260\n",
      "Train acc: 0.251, Val acc: 0.263\n",
      "Train acc: 0.252, Val acc: 0.249\n",
      "Train acc: 0.251, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.256, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.254, Val acc: 0.243\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.250, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.260\n",
      "Train acc: 0.255, Val acc: 0.260\n",
      "Train acc: 0.257, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.260\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.257\n",
      "Train acc: 0.257, Val acc: 0.251\n",
      "Train acc: 0.255, Val acc: 0.266\n",
      "Train acc: 0.255, Val acc: 0.254\n",
      "Train acc: 0.257, Val acc: 0.263\n",
      "Train acc: 0.256, Val acc: 0.260\n",
      "Train acc: 0.254, Val acc: 0.263\n",
      "Train acc: 0.254, Val acc: 0.260\n",
      "Train acc: 0.256, Val acc: 0.257\n",
      "Train acc: 0.255, Val acc: 0.266\n",
      "Train acc: 0.256, Val acc: 0.275\n",
      "Train acc: 0.254, Val acc: 0.266\n",
      "Train acc: 0.255, Val acc: 0.260\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n",
      "Train acc: 0.255, Val acc: 0.263\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m train_correct_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (train_x, train_y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[0;32m---> 13\u001b[0m     train_x \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     train_y \u001b[38;5;241m=\u001b[39m train_y\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cel_loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0)\n",
    "num_epochs = 100\n",
    "loader = train_aug_loader\n",
    "train_acc_hist = []\n",
    "val_acc_hist = []\n",
    "for epoch_idx in tqdm(range(num_epochs)):\n",
    "    # Set model to train mode - useful for layers such as BatchNorm or Dropout whose behaviors change between train/eval\n",
    "    model.train()\n",
    "    train_count = 0\n",
    "    train_correct_count = 0\n",
    "    for batch_idx, (train_x, train_y) in enumerate(loader):\n",
    "        train_x = train_x.float().to(device)\n",
    "        train_y = train_y.long().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(train_x)\n",
    "        loss = cel_loss(logits, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_hat = torch.argmax(logits, dim=-1)\n",
    "            train_correct_count += torch.sum(y_hat == train_y, axis=-1)\n",
    "            train_count += train_x.size(0)\n",
    "\n",
    "    train_acc = train_correct_count / train_count\n",
    "    train_acc_hist.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_count = 0\n",
    "    val_correct_count = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (val_x, val_y) in enumerate(val_loader):\n",
    "            val_x = val_x.float().to(device)\n",
    "            val_y = val_y.long().to(device)\n",
    "            logits = model(val_x).detach()\n",
    "            y_hat = torch.argmax(logits, dim=-1)\n",
    "            val_correct_count += torch.sum(y_hat == val_y, axis=-1)\n",
    "            val_count += val_x.size(0)\n",
    "    val_acc = val_correct_count / val_count\n",
    "    val_acc_hist.append(val_acc)\n",
    "\n",
    "    print('Train acc: {:.3f}, Val acc: {:.3f}'.format(train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10662"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.40406322479248047\n"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "val_count = 0\n",
    "val_correct_count = 0\n",
    "with torch.no_grad():\n",
    "    for idx, (val_x, val_y) in enumerate(test_loader):\n",
    "        val_x = val_x.float().to(device)\n",
    "        val_y = val_y.long().to(device)\n",
    "        logits = model(val_x).detach()\n",
    "        y_hat = torch.argmax(logits, dim=-1)\n",
    "        val_correct_count += torch.sum(y_hat == val_y, axis=-1)\n",
    "        val_count += val_x.size(0)\n",
    "val_acc = val_correct_count / val_count\n",
    "\n",
    "print(\"Test Accuracy:\", val_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(22, 64, kernel_size=(64, 1), stride=(1, 1), padding=(5, 0))\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 200, kernel_size=(64, 1), stride=(1, 1), padding=(5, 0))\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(200, 200, kernel_size=(64, 1), stride=(1, 1), padding=(5, 0))\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=2, end_dim=-1)\n",
      "  (linear1): Linear(in_features=11, out_features=11, bias=True)\n",
      "  (flatten_cnn): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_cnn): Linear(in_features=2200, out_features=4, bias=True)\n",
      "  (lstm1): LSTM(200, 64, num_layers=3, dropout=0.5)\n",
      "  (linear2): Linear(in_features=64, out_features=4, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
