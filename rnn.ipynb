{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from optuna import Trial, Study\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "from utils.training import train, best_torch_device\n",
    "from torchinfo import summary\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = best_torch_device()\n",
    "# device = torch.device('cpu')\n",
    "print(best_torch_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid = np.load(\"data/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"data/y_train_valid.npy\")\n",
    "person_train_valid = np.load(\"data/person_train_valid.npy\")\n",
    "\n",
    "X_train_aug = np.load(\"data/generated/frequency/X_train_augmented.npy\")\n",
    "y_train_aug = np.load(\"data/generated/frequency/y_train_augmented.npy\")\n",
    "\n",
    "X_test = np.load(\"data/X_test.npy\")\n",
    "y_test = np.load(\"data/y_test.npy\")\n",
    "person_test = np.load(\"data/person_test.npy\")\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_train_aug -= 769\n",
    "y_test -= 769\n",
    "\n",
    "X_train = X_train_valid[:1777]\n",
    "y_train = y_train_valid[:1777]\n",
    "X_valid = X_train_valid[1777:]\n",
    "y_valid = y_train_valid[1777:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8885, 22, 1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "class Permute(nn.Module):\n",
    "    def __init__(self, *dims):\n",
    "        super(Permute, self).__init__()\n",
    "        self.dims = dims\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.permute(*self.dims)\n",
    "    \n",
    "def train(model, optimizer, loader, val_loader, cel_loss, num_epochs):\n",
    "    train_acc_hist = []\n",
    "    val_acc_hist = []\n",
    "    for epoch_idx in tqdm(range(num_epochs)):\n",
    "        # Set model to train mode - useful for layers such as BatchNorm or Dropout whose behaviors change between train/eval\n",
    "        model.train()\n",
    "        train_count = 0\n",
    "        train_correct_count = 0\n",
    "        for batch_idx, (train_x, train_y) in enumerate(loader):\n",
    "            train_x = train_x.float().to(device)\n",
    "            train_y = train_y.long().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(train_x)\n",
    "            loss = cel_loss(logits, train_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_hat = torch.argmax(logits, dim=-1)\n",
    "                train_correct_count += torch.sum(y_hat == train_y, axis=-1)\n",
    "                train_count += train_x.size(0)\n",
    "\n",
    "        train_acc = train_correct_count / train_count\n",
    "        train_acc_hist.append(train_acc)\n",
    "\n",
    "        model.eval()\n",
    "        val_count = 0\n",
    "        val_correct_count = 0\n",
    "        with torch.no_grad():\n",
    "            for idx, (val_x, val_y) in enumerate(val_loader):\n",
    "                val_x = val_x.float().to(device)\n",
    "                val_y = val_y.long().to(device)\n",
    "                logits = model(val_x).detach()\n",
    "                y_hat = torch.argmax(logits, dim=-1)\n",
    "                val_correct_count += torch.sum(y_hat == val_y, axis=-1)\n",
    "                val_count += val_x.size(0)\n",
    "        val_acc = val_correct_count / val_count\n",
    "        val_acc_hist.append(val_acc)\n",
    "        print('Train acc: {:.3f}, Val acc: {:.3f}'.format(train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        conv1_filter_num = 32\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=22, out_channels=conv1_filter_num, kernel_size=(5, 1), padding=(5, 0)),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 1)),\n",
    "            nn.BatchNorm2d(conv1_filter_num),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        conv2_filter_num = 128\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=conv1_filter_num, out_channels=conv2_filter_num, kernel_size=(5, 1), padding=(5, 0)),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 1)),\n",
    "            nn.BatchNorm2d(conv2_filter_num),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        conv3_filter_num = 128\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=conv2_filter_num, out_channels=conv3_filter_num, kernel_size=(5, 1), padding=(5, 0)),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(3, 1)),\n",
    "            nn.BatchNorm2d(conv3_filter_num),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        conv_out_filter_size = 19\n",
    "        self.flatten = nn.Flatten(start_dim=2)\n",
    "        self.linear1 = nn.Linear(in_features=conv_out_filter_size, out_features=conv_out_filter_size)\n",
    "\n",
    "        self.flatten_cnn = nn.Flatten(start_dim=1)\n",
    "        self.linear_cnn = nn.Linear(in_features=conv_out_filter_size*conv3_filter_num, out_features=4)\n",
    "\n",
    "        self.tdd = nn.Linear(in_features=1000, out_features=50)\n",
    "\n",
    "        conv_rnn_filter_num = 50\n",
    "        self.conv_rnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=22, out_channels=conv_rnn_filter_num, kernel_size=(64, 1), padding=(5, 0)),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(7, 1)),\n",
    "            nn.BatchNorm2d(conv_rnn_filter_num),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.num_layers = 3\n",
    "        self.hidden_size = 30\n",
    "        self.lstm = nn.LSTM(input_size=conv3_filter_num, hidden_size=self.hidden_size, dropout=0.5, num_layers=self.num_layers)\n",
    "        # self.lstm = nn.LSTM(input_size=conv_rnn_filter_num, hidden_size=self.hidden_size, dropout=0.5, num_layers=self.num_layers)\n",
    "        \n",
    "        self.linear2 = nn.Linear(in_features=self.hidden_size, out_features=4) # (N, 4)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1) # the dim corresponds to num_output_classes=4\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x should have shape (N, H, L) = (N, 22, 1000), where\n",
    "            L = sequence length\n",
    "            N = batch size\n",
    "            H = input size\n",
    "        \"\"\"\n",
    "        (N, H, L) = x.shape\n",
    "\n",
    "        x = x.view((-1, 22, 1000, 1))\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        # x = self.linear1(x)\n",
    "        # x = self.flatten_cnn(x)\n",
    "        # x = self.linear_cnn(x)\n",
    "\n",
    "        # x = self.tdd(x)\n",
    "        # x = x.view((-1, 22, 1000, 1))\n",
    "        # x = self.conv_rnn(x)\n",
    "        # x = self.flatten(x)\n",
    "        x = x.permute(2, 0, 1) # permute to (L=time, N, H=channel_in)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # device = torch.device('mps')\n",
    "        # h0 = torch.randn(self.num_layers, N, self.hidden_size).to(device)\n",
    "        # c0 = torch.randn(self.num_layers, N, self.hidden_size).to(device)\n",
    "        # x, _ = self.lstm(x, (h0, c0))\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear2(x[-1]) # take the last time step\n",
    "        \n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.tdd = nn.Sequential(\n",
    "            nn.Linear(22, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(40)\n",
    "\n",
    "        self.num_layers = 5 # 3, 4\n",
    "        self.hidden_size = 20 # 20\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=40,\n",
    "            hidden_size=self.hidden_size,\n",
    "            dropout=0.5,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.linear2 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(20),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LazyLinear(out_features=4),\n",
    "        )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)  # the dim corresponds to num_output_classes=4\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x should have shape (N, H, L) = (N, 22, 1000), where\n",
    "            L = sequence length\n",
    "            N = batch size\n",
    "            H = input size\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1) # (N, 1000, 22)\n",
    "        x = self.tdd(x) # (N, 1000, 40)\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.bn(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # device = torch.device('mps')\n",
    "        # h0 = torch.randn(self.num_layers, self.hidden_size).to(device)\n",
    "        # c0 = torch.randn(self.num_layers, self.hidden_size).to(device)\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yubo/miniforge3/lib/python3.10/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "RNN                                      [128, 4]                  --\n",
       "├─Sequential: 1-1                        [128, 1000, 40]           --\n",
       "│    └─Linear: 2-1                       [128, 1000, 40]           920\n",
       "│    └─ReLU: 2-2                         [128, 1000, 40]           --\n",
       "│    └─Dropout: 2-3                      [128, 1000, 40]           --\n",
       "├─BatchNorm1d: 1-2                       [128, 40, 1000]           80\n",
       "├─LSTM: 1-3                              [128, 1000, 20]           18,400\n",
       "├─Sequential: 1-4                        [128, 4]                  --\n",
       "│    └─Flatten: 2-4                      [128, 20000]              --\n",
       "│    └─Linear: 2-5                       [128, 20]                 400,020\n",
       "│    └─ReLU: 2-6                         [128, 20]                 --\n",
       "│    └─BatchNorm1d: 2-7                  [128, 20]                 40\n",
       "│    └─Dropout: 2-8                      [128, 20]                 --\n",
       "│    └─Linear: 2-9                       [128, 4]                  84\n",
       "├─Softmax: 1-5                           [128, 4]                  --\n",
       "==========================================================================================\n",
       "Total params: 419,544\n",
       "Trainable params: 419,544\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.41\n",
       "==========================================================================================\n",
       "Input size (MB): 11.26\n",
       "Forward/backward pass size (MB): 102.45\n",
       "Params size (MB): 1.68\n",
       "Estimated Total Size (MB): 115.39\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsz = 128\n",
    "sample_device = torch.device('mps')\n",
    "sample_model = RNN().to(sample_device)\n",
    "test_input = torch.randn(128, 22, 1000).to(sample_device)\n",
    "print(sample_model(test_input).shape)\n",
    "summary(sample_model, (bsz, 22, 1000), device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 70 338 443\n",
      "(8885, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "bsz = 128\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train)), shuffle=True, batch_size=bsz)\n",
    "train_aug_loader = DataLoader(TensorDataset(torch.from_numpy(X_train_aug), torch.from_numpy(y_train_aug)), shuffle=True, batch_size=bsz)\n",
    "val_loader = DataLoader(TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid)), shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test)), shuffle=False)\n",
    "\n",
    "print(len(train_loader), len(train_aug_loader), len(val_loader), len(test_loader))\n",
    "\n",
    "print(X_train_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (tdd): Sequential(\n",
      "    (0): Linear(in_features=22, out_features=40, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lstm): LSTM(40, 20, num_layers=5, batch_first=True, dropout=0.5)\n",
      "  (linear2): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): LazyLinear(in_features=0, out_features=20, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): LazyLinear(in_features=0, out_features=4, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "torch.Size([128, 4])\n"
     ]
    }
   ],
   "source": [
    "model = RNN().to(device)\n",
    "print(model)\n",
    "num_chans, sequence_length = 22, 1000  # Image dimensions\n",
    "test_input = torch.randn(bsz, num_chans, sequence_length).to(device)\n",
    "print(model(test_input).shape)\n",
    "# pred = model(test_input)[0]\n",
    "# print(nn.CrossEntropyLoss()(pred, torch.from_numpy(y_train[0:1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644cf31890e4482e8f791e1d317e76e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.254, Val acc: 0.243\n",
      "Train acc: 0.279, Val acc: 0.263\n",
      "Train acc: 0.337, Val acc: 0.320\n",
      "Train acc: 0.359, Val acc: 0.334\n",
      "Train acc: 0.371, Val acc: 0.393\n",
      "Train acc: 0.395, Val acc: 0.376\n",
      "Train acc: 0.419, Val acc: 0.373\n",
      "Train acc: 0.427, Val acc: 0.388\n",
      "Train acc: 0.451, Val acc: 0.405\n",
      "Train acc: 0.461, Val acc: 0.393\n",
      "Train acc: 0.471, Val acc: 0.405\n",
      "Train acc: 0.481, Val acc: 0.402\n",
      "Train acc: 0.493, Val acc: 0.373\n",
      "Train acc: 0.501, Val acc: 0.402\n",
      "Train acc: 0.500, Val acc: 0.379\n",
      "Train acc: 0.513, Val acc: 0.414\n",
      "Train acc: 0.532, Val acc: 0.388\n",
      "Train acc: 0.524, Val acc: 0.361\n",
      "Train acc: 0.524, Val acc: 0.373\n",
      "Train acc: 0.552, Val acc: 0.376\n",
      "Train acc: 0.559, Val acc: 0.393\n",
      "Train acc: 0.558, Val acc: 0.361\n",
      "Train acc: 0.558, Val acc: 0.379\n",
      "Train acc: 0.558, Val acc: 0.373\n",
      "Train acc: 0.571, Val acc: 0.349\n",
      "Train acc: 0.588, Val acc: 0.396\n",
      "Train acc: 0.582, Val acc: 0.408\n",
      "Train acc: 0.591, Val acc: 0.405\n",
      "Train acc: 0.593, Val acc: 0.370\n",
      "Train acc: 0.609, Val acc: 0.355\n",
      "Train acc: 0.606, Val acc: 0.373\n",
      "Train acc: 0.613, Val acc: 0.367\n",
      "Train acc: 0.612, Val acc: 0.376\n",
      "Train acc: 0.623, Val acc: 0.370\n",
      "Train acc: 0.627, Val acc: 0.376\n",
      "Train acc: 0.629, Val acc: 0.352\n",
      "Train acc: 0.621, Val acc: 0.382\n",
      "Train acc: 0.623, Val acc: 0.352\n",
      "Train acc: 0.628, Val acc: 0.337\n",
      "Train acc: 0.642, Val acc: 0.361\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(train_x)\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m cel_loss(logits, train_y)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cel_loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.000005)\n",
    "num_epochs = 100\n",
    "loader = train_aug_loader\n",
    "\n",
    "best_model = model\n",
    "best_val = 0\n",
    "train_acc_hist = []\n",
    "val_acc_hist = []\n",
    "for epoch_idx in tqdm(range(num_epochs)):\n",
    "    # Set model to train mode - useful for layers such as BatchNorm or Dropout whose behaviors change between train/eval\n",
    "    model.train()\n",
    "    train_count = 0\n",
    "    train_correct_count = 0\n",
    "    for batch_idx, (train_x, train_y) in enumerate(loader):\n",
    "        train_x = train_x.float().to(device)\n",
    "        train_y = train_y.long().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(train_x)\n",
    "        loss = cel_loss(logits, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_hat = torch.argmax(logits, dim=-1)\n",
    "            train_correct_count += torch.sum(y_hat == train_y, axis=-1)\n",
    "            train_count += train_x.size(0)\n",
    "\n",
    "    train_acc = train_correct_count / train_count\n",
    "    train_acc_hist.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_count = 0\n",
    "    val_correct_count = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (val_x, val_y) in enumerate(val_loader):\n",
    "            val_x = val_x.float().to(device)\n",
    "            val_y = val_y.long().to(device)\n",
    "            logits = model(val_x).detach()\n",
    "            y_hat = torch.argmax(logits, dim=-1)\n",
    "            val_correct_count += torch.sum(y_hat == val_y, axis=-1)\n",
    "            val_count += val_x.size(0)\n",
    "    val_acc = val_correct_count / val_count\n",
    "    val_acc_hist.append(val_acc)\n",
    "    print('Train acc: {:.3f}, Val acc: {:.3f}'.format(train_acc, val_acc))\n",
    "\n",
    "    if val_acc > best_val:\n",
    "        best_val = val_acc\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4063205420970917\n"
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "val_count = 0\n",
    "val_correct_count = 0\n",
    "with torch.no_grad():\n",
    "    for idx, (val_x, val_y) in enumerate(test_loader):\n",
    "        val_x = val_x.float().to(device)\n",
    "        val_y = val_y.long().to(device)\n",
    "        logits = best_model(val_x).detach()\n",
    "        y_hat = torch.argmax(logits, dim=-1)\n",
    "        val_correct_count += torch.sum(y_hat == val_y, axis=-1)\n",
    "        val_count += val_x.size(0)\n",
    "val_acc = val_correct_count / val_count\n",
    "\n",
    "print(\"Test Accuracy:\", val_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4142, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
